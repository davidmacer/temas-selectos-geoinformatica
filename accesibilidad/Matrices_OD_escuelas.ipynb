{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores matrices Origen-Destino\n",
    "\n",
    "En el primer notebook de accesibiliodad implementamos nuestros modelos utilizando la distancia euclidiana. Esto es, desde luego, relativamente sencillo de calcular, sin embargo claramente no es lo ideal. El siguiente paso lógico es utilizar la conectividad sobre la red de calles.\n",
    "\n",
    "Hay muchísimas formas de obtener matrices de costo utilizando la red de calles, desde luego todas ellas van a tener algunas complicaciones, se necesitan más datos (la red de calles, dah) y es computacionalmente intensivo. En la documentación de access tenemos una [lista](https://access.readthedocs.io/en/latest/resources.html) de diferentes herramientas para crear estas matrices.\n",
    "\n",
    "Nosotros vamos a usar en este ejemplo [OSRM](http://project-osrm.org/) que es un motor de rutas que utiliza datos de OSM. Para esto tenemos una instalación de OSRM en un servidor de CentroGeo. Para acceder a ese servidor tienen que sacar una cuenta con su correo institucional en [tailscale](tailscale.com). Ya que tengan su cuenta necesitan seguir las [instrucciones](https://tailscale.com/download/windows) para instalar el cliente de tailscale en su plataforma. Ya con el cliente configurado pueden acceder a la interfaz gráfica aquí:\n",
    "\n",
    "http://100.67.66.19:9966/\n",
    "\n",
    "En lo que sigue de este notebook voy a usar datalab en lugar de la ip para escribir menos (para que eso funcione necesitan editar el hosts file de sus compus o el equivalente en windows).\n",
    "\n",
    "OSRM es un servidor que nos provee un API para hacer algunos cálculos de rutas. La documentación completa del API la pueden ver [aquí](http://project-osrm.org/docs/v5.24.0/api/#). Para hacer peticiones al API desde Python, vamos a usar la librería [requests](https://docs.python-requests.org/en/master/). Para empezar, hagamos una petición pidiendo la ruta y las instrucciones entre dos puntos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de ruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('http://100.67.66.19:5000/route/v1/driving/-99.14428918256026,19.351424122115958;-99.16261403345554,19.35211246418011?steps=true')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ven, es muy fácil de usar, desde luego la salida es un poco complicada, pero en el fondo es sólo un json, entonces es sencillo de parsear y utilizar como mejor nos convenga. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ejemplo de matriz\n",
    "\n",
    "Como nuestro problema básico ahorita no es obtener rutas sino calcular matrices origen destino, nos vamos a concentrar en ello en lugar de dar un paseo completo por el API de OSRM.\n",
    "\n",
    "El único servicio que vamos a necesitar el [table-service](http://project-osrm.org/docs/v5.24.0/api/#table-service) que toma dos listas de coordenadas y nos regresa las distancias (sobre la red) y costos entre todos los pares de coordenadas. Justo lo que queremos.\n",
    "\n",
    "Para empezar a trabajar con nuestros datos, leamos los datos de centroides de áreas verdes y agebs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "agebs_zmvm_centroides = gpd.read_file('./datos/agebs_zmvm_centroides.gpkg', layer='agebs_zmvm_centroides')\n",
    "escuelas = gpd.read_file(\"./datos/escuelas_zmvm_centroides.gpkg\", layer='escuelas_zmvm_centroides')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomemos sólo los primeros registros de cada una, ahorita sólo queremos entender la estructura que nos regresa el API y cómo crear la matriz que queremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos los primeros 5 registros de cada dataframe\n",
    "origenes = agebs_zmvm_centroides.head()\n",
    "destinos = escuelas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos que manufacturar el string de la petición al API. Viendo la documentación, el servicio nos regresa la distancia (o el costo) entre todos los pares de coordenadas, o bien, podemos identificar un par de coordenadas como el origen y entonces nos regrasa la distancia desde ese punto a todos los demás. Por la estructura de nuestros datos, lo más fácil es tomar el primer punto de origen y calcular las distancias a todos los demás y después iterar sobre los origenes.\n",
    "\n",
    "\n",
    "Una petición del tipo que queremos se ve así:\n",
    "\n",
    "````bash\n",
    "curl 'http://router.project-osrm.org/table/v1/driving/13.388860,52.517037;13.397634,52.529407;13.428555,52.523219?sources=0'\n",
    "````\n",
    "\n",
    "El primer par de coordenadas es el origen y el resto son los destinos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings de las peticiones\n",
    "\n",
    "Ahora necesitamos transformar nuestros datos en los strings que necesitamos para hacer las peticiones al API. El primer paso es hacer una lista con las coordenadas de los destinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una lista de las latitudes y longitudes\n",
    "ys = destinos.geometry.to_crs(4326).y.to_list()\n",
    "xs = destinos.geometry.to_crs(4326).x.to_list()\n",
    "# zipeamos la lista\n",
    "pares = list(zip(ys,xs))\n",
    "pares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos la lista en el string que necesitamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for p in pares:\n",
    "    a = str(p[1]) + \",\" + str(p[0])\n",
    "    s.append(a)\n",
    "destinos_str = \";\".join(s)\n",
    "destinos_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el string del origen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origen_str = str(origenes.to_crs(4326).iloc[0].geometry.x) + ',' + str(origenes.to_crs(4326).iloc[0].geometry.y)\n",
    "origen_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el string completo del request al API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://100.67.66.19:5000/table/v1/driving/'\n",
    "full_request = base_url + origen_str + ';' + destinos_str + '?sources=0'\n",
    "full_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Petición\n",
    "Ahora podemos hacer la petición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(full_request)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a la documentación de OSRM, lo que nos regresa el API es un json que en la entrada `durations` tiene las duraciones de los viajes a cada uno de los destinos conservando el índice en el que los mandamos, las demás entradas contienen información adicional que en este caso no vamos a utilizar. Entonces, lo que necesitamos hacer es simplemete extraer la lista de durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()['durations'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer elemento de la lista no lo queremos, es la duración entre el origen y el origen mismo, los demás son los buenos. Ahora necesitamos estructurar los datos de forma que podamos obtener el dataframe de costos como lo necesitamos para `access`. Fíjense que tenemos el id del origen en `origenes.iloc[0].CVEGEO` y los ids de los destinos en el dataframe correspondiente, entonces es relativamente fácil hacur un nuevo dataframe con origen, destino y costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costos = destinos.copy()[['id_escuela']].rename({'id_escuela':'destino'}, axis=1)\n",
    "costos['costo'] = r.json()['durations'][0][1:]\n",
    "costos['origen'] = origenes.iloc[0].CVEGEO\n",
    "costos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo en una función\n",
    "Perfecto, tenemos el pedazo de la matriz que corresponde al primer origen, ahora ya sólo necesitamos iterar sobre todos los orígenes y concatenar el resultado en un sólo dataframe.\n",
    "\n",
    "Para hacer todo más fácil, lo que más nos conviene es empaquetar todo el flujo que hemos hecho en una sóla función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_od_matrix(origenes, destinos):\n",
    "    base_url = 'http://100.67.66.19:5000/table/v1/driving/'\n",
    "    # primero hacemos todo el string de los destinos\n",
    "    ys = destinos.geometry.to_crs(4326).y.to_list()\n",
    "    xs = destinos.geometry.to_crs(4326).x.to_list()\n",
    "    pares = zip(ys,xs)\n",
    "    s = []\n",
    "    for p in pares:\n",
    "        a = str(p[1]) + \",\" + str(p[0])\n",
    "        s.append(a)\n",
    "    destinos_str = \";\".join(s)\n",
    "    #para cada origen hacemos la patición y guardamos el resultado\n",
    "    origenes = origenes.to_crs(4326)\n",
    "    costos = [] # acá vamos a ir guardando los resultados para cada origen\n",
    "    for _, row in origenes.iterrows():\n",
    "        origen_str = str(row.geometry.x) + ',' + str(row.geometry.y)\n",
    "        req = base_url + origen_str + ';' + destinos_str + '?sources=0'\n",
    "        r = requests.get(req)\n",
    "        resultado = r.json()\n",
    "        if resultado['code'] == 'Ok':\n",
    "            c = destinos.copy()[['id_escuela']].rename({'id_escuela':'destino'}, axis=1)\n",
    "            c['costo'] = resultado['durations'][0][1:]\n",
    "            c['origen'] = row.CVEGEO\n",
    "            costos.append(c)\n",
    "        else:\n",
    "            print(f\"something went wrong with origin {row.CVEGEO}\")\n",
    "    costos = pd.concat(costos).reset_index().drop(columns=['index'])\n",
    "    return costos\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos nuestra función con los datos chiquitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costos = get_od_matrix(origenes, destinos)\n",
    "costos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con nuestra función, podemos ahora sí hacer la matriz completa, sólo que eso evidentemente va a tardar mucho. Una forma de ganarle tiempo es correr el loop de la función en paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def parallel_get_od_matrix(origenes, destinos, njobs=2):\n",
    "    def process_row(_, row):\n",
    "            origen_str = str(row.geometry.x) + ',' + str(row.geometry.y)\n",
    "            req = base_url + origen_str + ';' + destinos_str + '?sources=0'\n",
    "            r = requests.get(req)\n",
    "            resultado = r.json()\n",
    "            if resultado['code'] == 'Ok':\n",
    "                c = destinos.copy()[['id_escuela']].rename({'id_escuela':'destino'}, axis=1)\n",
    "                c['costo'] = resultado['durations'][0][1:]\n",
    "                c['origen'] = row.CVEGEO\n",
    "            else:\n",
    "                print(f\"something went wrong with origin {row.CVEGEO}\")\n",
    "            return c\n",
    "    base_url = 'http://100.67.66.19:5000/table/v1/driving/'\n",
    "    # primero hacemos todo el string de los destinos\n",
    "    ys = destinos.geometry.to_crs(4326).y.to_list()\n",
    "    xs = destinos.geometry.to_crs(4326).x.to_list()\n",
    "    pares = zip(ys,xs)\n",
    "    s = []\n",
    "    for p in pares:\n",
    "        a = str(p[1]) + \",\" + str(p[0])\n",
    "        s.append(a)\n",
    "    destinos_str = \";\".join(s)\n",
    "    #para cada origen hacemos la patición y guardamos el resultado\n",
    "    origenes = origenes.to_crs(4326)\n",
    "    costos = [] # acá vamos a ir guardando los resultados para cada origen\n",
    "    costos = Parallel(n_jobs=njobs)(delayed(process_row)(_,row) for _, row in origenes.iterrows())\n",
    "    costos = pd.concat(costos).reset_index().drop(columns=['index'])\n",
    "    return costos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos nuestra nueva función y comparamos los tiempos de ejecución (noten que estamos usando sólo dos trabajos simultaneamente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ganamos un 30%!!!!\n",
    "\n",
    "Con esta función podemos ya correr el algoritmo para la base de datos completa. Se va a tardar muchísimo, no lo intenten en casa!!!! \n",
    "\n",
    "**NOTA:** Pueden jugar un poco con el valor de njobs, pero recuerden que debe ser menor al número de hilos de su procesador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz completa\n",
    "\n",
    "Pues ahora ya estamos listos para hacer la matriz inmensa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matriz_completa = parallel_get_od_matrix(agebs_zmvm_centroides, escuelas)\n",
    "matriz_completa.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La guardamos como pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_completa.to_csv(\"./datos/matriz_escuelas_od_walking.csv\". index=False)\n",
    "matriz_completa.to_file(\"./datos/matriz_escuelas_od_walking.gpkg\", layer='matriz_escuelas_od_walking', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
